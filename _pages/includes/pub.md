# üìö Publications
\# Corresponding author

## Journal

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCV 2024</div><img src='images/pub/IJCV_2024_LSKNet.png' alt="sym" width="350"  >
</div></div>
<div class='paper-box-text' markdown="1">

[LSKNet: A foundation lightweight backbone for remote sensing **(IJCV)**](https://link.springer.com/article/10.1007/s11263-024-02247-9)

**Yuxuan Li**, Xiang Li\#, Yimian Dai, Qibin Hou, Li Liu,  Yongxiang Liu, Ming-Ming Cheng, Jian Yang\#

[[**Paper**]](https://arxiv.org/pdf/2403.11735) 
[[**BibTex**]](./resources/bibtex/IJCV_2024_LSKNet.txt) 
[[**Demo Video**]](https://www.bilibili.com/video/BV1Wu4y137Zz/?share_source=copy_web&vd_source=b37c2bd32246c553d6c1713fc1d9f29f) 
[[**Code**]](https://github.com/zcablii/LSKNet)[![](https://img.shields.io/github/stars/zcablii/LSKNet?style=social)](https://github.com/zcablii/LSKNet)


LSKNet can dynamically adjust its large spatial receptive field to better model the ranging context of various categories of objects in remote sensing scenarios.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVMJ 2024</div><img src='images/pub/APF-GAN.png' alt="sym" width="350"  >
</div></div>
<div class='paper-box-text' markdown="1">

[APF-GAN:Exploring asymmetric pre-training and fine-tuning strategy for conditional generativeadversarial network **(CVMJ)**](https://go.gale.com/ps/i.do?id=GALE%7CA777600258&sid=googleScholar&v=2.1&it=r&linkaccess=abs&issn=20960662&p=AONE&sw=w&userGroupName=anon%7E539354e6&aty=open-web-entry)

**Yuxuan Li**, Lingfeng Yang, Xiang Li\#

[[**Paper**]](https://link.springer.com/content/pdf/10.1007/s41095-023-0357-1.pdf)
[[**Code**]](https://github.com/zcablii/APF-GAN-jittor) 

The APF-GAN model improves GAN-based image segmentation, surpassing GauGAN and winning the Second Jittor AI Challenge.

</div>
</div>

## Conference

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2024</div><img src='images/pub/AAAI_2026_SM3Det.png' alt="sym" width="350">
</div></div>
<div class='paper-box-text' markdown="1">

[SM3Det: A Unified Model for Multi-Modal Remote Sensing Object Detection **(AAAI 2026 Oral)**](https://arxiv.org/abs/2412.20665)

**Yuxuan Li**, Xiang Li\#, Yunheng Li, Yicheng Zhang, Yimian Dai, Qibin Hou, Ming-Ming Cheng and Jian Yang\#

[[**Paper**]](https://arxiv.org/abs/2412.20665)
[[**BibTex**]](./resources/bibtex/AAAI_2026_SM3Det.txt) 
[[**Code**]](https://github.com/zcablii/SM3Det)[![](https://img.shields.io/github/stars/zcablii/SM3Det?style=social)](https://github.com/zcablii/SM3Det)
[[**Áü•‰πé‰∏ìÊ†è**]](https://zhuanlan.zhihu.com/p/15685945444)

This paper introduces SM3Det, a unified remote sensing model designed to handle multi-modal, multi-task object detection by leveraging a sparse Mixture-of-Experts backbone and dynamic optimization.


</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2024</div><img src='images/pub/NeurIPS_2024_SARDet-100K.png' alt="sym" width="350">
</div></div>
<div class='paper-box-text' markdown="1">

[SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection **(NeurIPS 2024 Spotlight)**](https://arxiv.org/abs/2403.06534)

**Yuxuan Li**, Xiang Li\#, Weijie Li, Qibin Hou, Li Liu, Ming-Ming Cheng, Jian Yang\#

[[**Paper**]](https://arxiv.org/pdf/2403.06534)
[[**BibTex**]](./resources/bibtex/NeurIPS_2024_Sardet.txt) 
[[**Code**]](https://github.com/zcablii/SARDet_100K)[![](https://img.shields.io/github/stars/zcablii/SARDet_100K?style=social)](https://github.com/zcablii/SARDet_100K)
[[**Áü•‰πé‰∏ìÊ†è**]](https://zhuanlan.zhihu.com/p/686785188)


SARDet-100K, the first large-scale multi-class SAR object detection dataset, along with the proposed MSFA pretraining framework, addresses domain and model disparities, significantly improving SAR object detection performance and advancing the field.

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2023</div><img src='images/pub/ICCV_2023_LSKNet.png' alt="sym" width="350"  >
</div></div>
<div class='paper-box-text' markdown="1">

[Large Selective Kernel Network for Remote Sensing Object Detection **(ICCV 2023)**](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Large_Selective_Kernel_Network_for_Remote_Sensing_Object_Detection_ICCV_2023_paper.html)

**Yuxuan Li**, Qibin Hou, Zhaohui Zheng, Ming-Ming Cheng, Jian Yang\#, Xiang Li\#

[[**Paper**]](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Large_Selective_Kernel_Network_for_Remote_Sensing_Object_Detection_ICCV_2023_paper.pdf) 
[[**BibTex**]](./resources/bibtex/ICCV_2023_LSKNet.txt) 
[[**Demo Video**]](https://www.bilibili.com/video/BV1Fc411y7D4/?spm_id_from=333.999.0.0&vd_source=5104238e9227b73c64ac2ac51092afcd) 
[[**Report/Forum**]](https://www.bilibili.com/video/BV1yc411Q7Pb/?vd_source=b787fb942d4c0010351265dbce7646d3) 
[[**Code**]](https://github.com/zcablii/LSKNet)[![](https://img.shields.io/github/stars/zcablii/LSKNet?style=social)](https://github.com/zcablii/LSKNet)
[[**Áü•‰πé‰∏ìÊ†è**]](https://zhuanlan.zhihu.com/p/614449075)


LSKNet can dynamically adjust its large spatial receptive field to better model the ranging context of various categories of objects in remote sensing scenarios.

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACCV 2022</div><img src='images/pub/ACCV_2022_SGE.png' alt="sym" width="350">
</div></div>
<div class='paper-box-text' markdown="1">

[Spatial group-wise enhance: Enhancing semantic feature learning in CNN **(ACCV 2022)**](https://openaccess.thecvf.com/content/ACCV2022/html/Li_Spatial_Group-wise_Enhance_Enhancing_Semantic_Feature_Learning_in_CNN_ACCV_2022_paper.html)

**Yuxuan Li**, Xiang Li\#, Jian Yang

[[**Paper**]](https://openaccess.thecvf.com/content/ACCV2022/papers/Li_Spatial_Group-wise_Enhance_Enhancing_Semantic_Feature_Learning_in_CNN_ACCV_2022_paper.pdf)
[[**BibTex**]](./resources/bibtex/ACCV_2022_SGE.txt) 
[[**Code**]][![](https://img.shields.io/github/stars/implus/PytorchInsight?style=social)](https://github.com/implus/PytorchInsight)
[[**Áü•‰πé‰∏ìÊ†è**]](https://zhuanlan.zhihu.com/p/66928045)

The Spatial Group-wise Enhance (SGE) module improves CNN performance by generating accurate spatial attention masks through local-global similarity within semantic groups, achieving notable accuracy gains on ImageNet and COCO tasks with minimal overhead.

</div>
</div>

# üìÉ Other Publications

### [Visual Instruction Pretraining for Domain-Specific Foundation Models](http://arxiv.org/abs/2509.17562)
**Preprint**, ***2025***  
**Yuxuan Li**, Yicheng Zhang, Wenhao Tang, Yimian Dai, Ming-Ming Cheng, Xiang Li\#, and Jian Yang\#
[[**Paper**]](http://arxiv.org/abs/2509.17562)  

---

### [RSAR: Restricted State Angle Resolver and Rotated SAR Benchmark](https://arxiv.org/abs/2501.04440)
**CVPR**, ***2024***  
Xin Zhang, Xue Yang, **Yuxuan Li**, Jian Yang, Ming-Ming Cheng, Xiang Li  
[[**Paper**]](https://arxiv.org/abs/2501.04440)  

---

### [DenseVLM: A Retrieval and Decoupled Alignment Framework for Open-Vocabulary Dense Prediction](https://arxiv.org/abs/2412.06244)
**Preprint**, ***2024***  
Yunheng Li, **Yuxuan Li**, Quansheng Zeng, Wenhai Wang, Qibin Hou, Ming-Ming Cheng  
[[**Paper**]](https://arxiv.org/abs/2412.06244)  

---

### [Strip R-CNN: Large Strip Convolution for Remote Sensing Object Detection](https://arxiv.org/abs/2501.03775)
**Preprint**, ***2024***  
Xinbin Yuan, Zhaohui Zheng, **Yuxuan Li**, Xialei Liu, Li Liu, Xiang Li, Qibin Hou, Ming-Ming Cheng  
[[**Paper**]](https://arxiv.org/abs/2501.03775)  

---

### [GrokLST: Towards High-Resolution Benchmark and Toolkit for Land Surface Temperature Downscaling](https://arxiv.org/abs/2409.19835)
**Preprint**, ***2024***  
Qun Dai, Chunyang Yuan, Yimian Dai, **Yuxuan Li**, Xiang Li, Kang Ni, Jianhui Xu, Xiangbo Shu, Jian Yang  
[[**Paper**]](https://arxiv.org/abs/2409.19835)  

---

### [Pick of the Bunch: Detecting Infrared Small Targets Beyond Hit-Miss Trade-Offs via Selective Rank-Aware Attention](https://ieeexplore.ieee.org/abstract/document/10677425)
**IEEE TGRS**, ***2024***  
Yimian Dai, Peiwen Pan, **Yuxuan Li**, et al.  
[[**Paper**]](https://arxiv.org/pdf/2408.03717)  

---

### [Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?](https://arxiv.org/abs/2305.12954)
**Preprint**, ***2023***  
Zheng Li\*, **Yuxuan Li\***, Penghai Zhao, et al.  
[[**Paper**]](https://arxiv.org/abs/2305.12954)  

---

### [DenoDet: Attention as Deformable Multi-Subspace Feature Denoising for Target Detection in SAR Images](https://arxiv.org/abs/2406.02833)
**Transactions on Aerospace and Electronic Systems**, ***2024***  
Yimian Dai, Minrui Zou, **Yuxuan Li**, et al.  
[[**Paper**]](https://ieeexplore.ieee.org/abstract/document/10770564)  

